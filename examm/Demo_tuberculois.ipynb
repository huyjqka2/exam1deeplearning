{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eq6JowrRfeA6"
   },
   "source": [
    "# Using Resnet for chest X-ray Tuberculosis classification"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zf_sNoXv1CH0",
    "outputId": "c559c0c7-b5b7-45d4-dbf4-997a68a78312",
    "ExecuteTime": {
     "end_time": "2025-10-08T07:01:38.146109Z",
     "start_time": "2025-10-08T07:01:06.322339Z"
    }
   },
   "source": [
    "import os\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K3yX_PIkCJSb",
    "ExecuteTime": {
     "end_time": "2025-10-08T07:02:01.720075Z",
     "start_time": "2025-10-08T07:02:01.715517Z"
    }
   },
   "source": [
    "# Define the data directory\n",
    "data_dir = r'G:\\deeplearning\\exam1deeplearning\\data\\TB_Chest_Radiography_Database'\n",
    "# Define model checkpoints directory\n",
    "save_dir = \"checkpoints\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mud_PJfqBFq8",
    "ExecuteTime": {
     "end_time": "2025-10-08T07:02:04.006343Z",
     "start_time": "2025-10-08T07:02:03.479691Z"
    }
   },
   "source": [
    "# ---------------------------\n",
    "# Reproducibility & device\n",
    "# ---------------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: metrics\n",
    "# ---------------------------\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_probs, y_pred = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb).squeeze(-1).cpu()  # [batch]\n",
    "            probs = torch.sigmoid(logits).numpy()\n",
    "            preds = (probs >= 0.5).astype(int)\n",
    "            y_probs.extend(probs.tolist())\n",
    "            y_pred.extend(preds.tolist())\n",
    "            y_true.extend(yb.numpy().tolist())\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_probs)\n",
    "    except Exception:\n",
    "        auc = float(\"nan\")\n",
    "    cls_report = classification_report(y_true, y_pred, digits=4)\n",
    "    return acc, auc, cls_report"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V8mEz0VkBKL0",
    "ExecuteTime": {
     "end_time": "2025-10-07T17:12:34.264814Z",
     "start_time": "2025-10-07T17:12:34.192547Z"
    }
   },
   "source": [
    "set_seed(42)\n",
    "\n",
    "# transforms\n",
    "tf = transforms.Compose([\n",
    "      transforms.RandomResizedCrop((224,224)),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "  ])\n",
    "\n",
    "full_ds = datasets.ImageFolder(os.path.join(data_dir), transform=tf)\n",
    "# Store class_to_idx before splitting\n",
    "class_to_idx = full_ds.class_to_idx\n",
    "\n",
    "train_len = int(len(full_ds)*0.8)\n",
    "val_len = len(full_ds) - train_len\n",
    "train_ds, val_ds = random_split(full_ds, [train_len, val_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=1)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0w5ohgv3fUQY",
    "outputId": "ba5e98ac-fa8a-437f-b1e6-a94d90261e1a",
    "ExecuteTime": {
     "end_time": "2025-10-07T17:14:25.518190Z",
     "start_time": "2025-10-07T17:12:37.141725Z"
    }
   },
   "source": [
    "# model:resnet50 -> single logit output\n",
    "# using pretrained with weights='DEFAULT'\n",
    "# training from scratch with weights=None\n",
    "model = models.resnet50(weights=None)\n",
    "\n",
    "for param in model.parameters():\n",
    "      param.requires_grad = True  # fine-tune all (or set False to freeze)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)  # single logit\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "best_auc = 0.0\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in tqdm(train_loader):\n",
    "        xb, yb = xb.to(device), yb.float().to(device)\n",
    "        logits = model(xb).squeeze(-1)  # [batch]\n",
    "        loss = criterion(logits, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    val_acc, val_auc, val_report = evaluate_model(model, val_loader)\n",
    "    scheduler.step(val_loss := train_loss)  # or use val_auc etc\n",
    "    print(f\"[Epoch {epoch}] train_loss={train_loss:.4f} val_acc={val_acc:.4f} val_auc={val_auc:.4f} \\n {val_report}\")\n",
    "\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        ckpt = os.path.join(save_dir, \"tb_resnet50_best.pt\")\n",
    "        torch.save({\"model_state\": model.state_dict(), \"class_to_idx\": class_to_idx}, ckpt)\n",
    "        print(f\"  Saved best checkpoint to {ckpt}\")\n",
    "\n",
    "  # final eval\n",
    "test_acc, test_auc, test_report = evaluate_model(model, val_loader)\n",
    "print(f\"Final val acc={test_acc:.4f}, auc={test_auc:.4f} \\n {test_report}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [00:41<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] train_loss=0.2875 val_acc=0.8964 val_auc=0.9482 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9734    0.8990    0.9347       693\n",
      "           1     0.6500    0.8844    0.7493       147\n",
      "\n",
      "    accuracy                         0.8964       840\n",
      "   macro avg     0.8117    0.8917    0.8420       840\n",
      "weighted avg     0.9168    0.8964    0.9023       840\n",
      "\n",
      "  Saved best checkpoint to checkpoints\\tb_resnet50_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [00:42<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train_loss=0.2106 val_acc=0.9119 val_auc=0.9431 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9307    0.9457       693\n",
      "           1     0.7160    0.8231    0.7658       147\n",
      "\n",
      "    accuracy                         0.9119       840\n",
      "   macro avg     0.8386    0.8769    0.8558       840\n",
      "weighted avg     0.9183    0.9119    0.9143       840\n",
      "\n",
      "Final val acc=0.9179, auc=0.9417 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9643    0.9351    0.9495       693\n",
      "           1     0.7321    0.8367    0.7810       147\n",
      "\n",
      "    accuracy                         0.9179       840\n",
      "   macro avg     0.8482    0.8859    0.8652       840\n",
      "weighted avg     0.9237    0.9179    0.9200       840\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "M√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi 2 epoch tr√™n t·∫≠p d·ªØ li·ªáu ph√¢n lo·∫°i nh·ªã ph√¢n (2 l·ªõp: 0 v√† 1).\n",
    "K·∫øt qu·∫£ th·ªÉ hi·ªán hi·ªáu su·∫•t cao v√† ·ªïn ƒë·ªãnh qua t·ª´ng giai ƒëo·∫°n hu·∫•n luy·ªán.\n",
    "\n",
    "üîπ K·∫øt qu·∫£ Epoch 0\n",
    "\n",
    "Train loss: 0.2875 ‚Üí m√¥ h√¨nh b·∫Øt ƒë·∫ßu h·ªçc t·ªët, sai s·ªë trung b√¨nh th·∫•p.\n",
    "\n",
    "Validation accuracy: 89.6%\n",
    "\n",
    "AUC: 0.9482 ‚Üí Kh·∫£ nƒÉng ph√¢n bi·ªát gi·ªØa hai l·ªõp r·∫•t t·ªët.\n",
    "| L·ªõp | Precision | Recall | F1-score |\n",
    "| --- | --------- | ------ | -------- |\n",
    "| 0   | 0.9734    | 0.8990 | 0.9347   |\n",
    "| 1   | 0.6500    | 0.8844 | 0.7493   |\n",
    "\n",
    "‚Üí L·ªõp 0 (√¢m t√≠nh) chi·∫øm ƒëa s·ªë v√† ƒë∆∞·ª£c nh·∫≠n di·ªán r·∫•t t·ªët.\n",
    "‚Üí L·ªõp 1 (d∆∞∆°ng t√≠nh) c√≥ recall cao (m√¥ h√¨nh b·∫Øt ƒë∆∞·ª£c h·∫ßu h·∫øt ca d∆∞∆°ng) nh∆∞ng precision th·∫•p h∆°n, nghƒ©a l√† v·∫´n c√≥ m·ªôt s·ªë d·ª± ƒëo√°n d∆∞∆°ng sai.\n",
    "\n",
    "üîπ K·∫øt qu·∫£ Epoch 1\n",
    "\n",
    "Train loss: 0.2106 ‚Üí ti·∫øp t·ª•c gi·∫£m, m√¥ h√¨nh h·ªçc ·ªïn ƒë·ªãnh h∆°n.\n",
    "\n",
    "Validation accuracy: 91.2%\n",
    "\n",
    "AUC: 0.9431 ‚Üí g·∫ßn nh∆∞ kh√¥ng gi·∫£m, v·∫´n duy tr√¨ kh·∫£ nƒÉng ph√¢n bi·ªát t·ªët.\n",
    "| L·ªõp | Precision | Recall | F1-score |\n",
    "| --- | --------- | ------ | -------- |\n",
    "| 0   | 0.9613    | 0.9307 | 0.9457   |\n",
    "| 1   | 0.7160    | 0.8231 | 0.7658   |\n",
    "\n",
    "‚Üí Hi·ªáu su·∫•t l·ªõp thi·ªÉu s·ªë (1) ƒë∆∞·ª£c c·∫£i thi·ªán r√µ r·ªát: recall gi·ªØ ·ªü m·ª©c cao (82%), precision tƒÉng t·ª´ 65% l√™n 71%.\n",
    "‚Üí M√¥ h√¨nh kh√¥ng b·ªã overfitting, kh·∫£ nƒÉng kh√°i qu√°t v·∫´n t·ªët.\n",
    "\n",
    "üîπ ƒê√°nh gi√° cu·ªëi c√πng\n",
    "\n",
    "Final accuracy: 91.8%\n",
    "\n",
    "Final AUC: 0.9417\n",
    "| L·ªõp | Precision | Recall | F1-score |\n",
    "| --- | --------- | ------ | -------- |\n",
    "| 0   | 0.9643    | 0.9351 | 0.9495   |\n",
    "| 1   | 0.7321    | 0.8367 | 0.7810   |\n",
    "\n",
    "‚Üí M√¥ h√¨nh ƒë·∫°t hi·ªáu su·∫•t cao tr√™n c·∫£ hai l·ªõp, ƒë·∫∑c bi·ªát v·∫´n duy tr√¨ ƒë·ªô ch√≠nh x√°c cao tr√™n l·ªõp thi·ªÉu s·ªë.\n",
    "‚Üí AUC > 0.94 cho th·∫•y m√¥ h√¨nh ph√¢n bi·ªát hai l·ªõp t·ªët, ph√π h·ª£p v·ªõi b√†i to√°n y sinh ho·∫∑c ph√°t hi·ªán b·ªánh c√≥ m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
